
rocket propulsion elements

effective altruism global:
- https://www.eaglobal.org/events/ea-global-2017-uk/
- https://www.youtube.com/channel/UCEfASxwPxzsHlG5Rf1-4K9w

can RL agents always be reasonable when framerate switches to 30fps to 60 or higher? If they are influenced by this then it seems like the error signal attenuation still applies right? So at that point, why not just create a much simpler policy-only optimization process?

also, pay very, very close attention to human's failure modes as well, as I don't think this has been developed in the community yet

tiny bit of math and workable code: https://towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2
env: https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py
more complex running code: https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html

also see how humans actually do RL too. How can they correlate long distance reward signals? Are they even good at such a task? It seems like I can somehow use attention as this mechanism that spans multiple time frames, so as to make the RL capabilities more pronounced, as that acts kinda like a skip connection

so the model-based RL agents seems interesting, because it can do fundamental experiments in the world to build an accurate model, then use that model as a proxy for the real world, then do experiments on them, instead of on the real world

https://www.techrepublic.com/article/natural-language-processing-a-cheat-sheet/

how do ppl actually build chatbots from language models? In other words, how to use language models flexibly and in 1 domain. "how chatbots are made"

"neural turing machine" sounds very, very impressive, so look into that

https://arxiv.org/pdf/1709.08568.pdf

superglue: a stickier benchmark for general-purpose language understanding systems: https://w4ngatang.github.io/static/papers/superglue.pdf
original glue benchmark: https://openreview.net/pdf?id=rJ4km2R5t7

"feature attribution, I guess they compute gradients all the way to the input and use that to construct heatmaps of which voxels are most important for a classification". Actually, the heatmaps can be generated with the last CNN layer before the activation. Anyway, bunch of links:
- https://distill.pub/2020/attribution-baselines/
- https://cloud.google.com/ai-platform/prediction/docs/ai-explanations/overview
- (2018) https://mlconf.com/sessions/interpretability-beyond-feature-attribution-quant/
- https://deep.ghost.io/simple-feature-attribution/
- https://towardsdatascience.com/one-feature-attribution-method-to-supposedly-rule-them-all-shapley-values-f3e04534983d
- interpretability beyond feature attribution: quantitative testing with concept activation vectors: https://arxiv.org/pdf/1711.11279.pdf

"robustify black-box controllers from neural nets"

deep RL from human preferences: https://arxiv.org/pdf/1706.03741.pdf, sounds familiar
planning chemical syntheses with deep NNs and symbolic AI: https://www.nature.com/articles/nature25978, alphago-inspired architecture
scaling laws for neural language models: https://arxiv.org/pdf/2001.08361.pdf
learning the difference that makes a difference with counterfactually-augmented data: https://arxiv.org/pdf/1909.12434.pdf
linformer: self-attention with linear complexity: https://arxiv.org/pdf/2006.04768.pdf

distillation & amplification:
- alphago zero and the foom debate: https://intelligence.org/2017/10/20/alphago/
- https://ai-alignment.com/alphago-zero-and-capability-amplification-ede767bb8446
- https://ai-alignment.com/benign-model-free-rl-4aae8c97e385
- https://ai-alignment.com/policy-amplification-6a70cbee4f34
- "capability vs policy amplification"
- https://intelligence.org/2018/05/19/challenges-to-christianos-capability-amplification-proposal/
- https://ai-alignment.com/iterated-distillation-and-amplification-157debfd1616

read more into inverse RL, seems like a very promising way to go about this

read over russell's papers: https://people.eecs.berkeley.edu/~russell/research/future/

"expert iteration", thinking fast and slow with DL and tree search: https://arxiv.org/pdf/1705.08439.pdf
neural architecture search with RL: https://arxiv.org/pdf/1611.01578.pdf
neural architecture search: a survey: https://arxiv.org/pdf/1808.05377.pdf

turn faces into anime girls. May be real guy -> anime guy/girl, and real girl -> anime guy/girl as well. Devise a way of switching the network back and fourth, to practice inputting in explicit meaning. This should be the first step in actually extracting information out of a system

can RL from pixels be as efficient as RL from state? https://bair.berkeley.edu/blog/2020/07/19/curl-rad/

discovering RL algorithms: https://arxiv.org/pdf/2007.08794.pdf

pipeline stuff (the concurrent idea in CPUs and stuff): https://cs.stanford.edu/~matei/papers/2019/sosp_pipedream.pdf

squad:
- know what you don't know: unanswerable questions for squad: https://arxiv.org/pdf/1806.03822.pdf
- squad: 100k+ questions for machine comprehension of text: https://nlp.stanford.edu/pubs/rajpurkar2016squad.pdf

paragraph stuff, "paragraph recognition:
- http://www.tbluche.com/files/Goog2017.pdf
- scan, attend, and read: end-to-end handwritten paragraph recognition with MDLSTM attention: https://arxiv.org/pdf/1604.03286.pdf

covid stuff:
- https://connect.biorxiv.org/relate/content/181
- continual bert: continual learning for adaptive extractive summarization of covid-19 literature: https://arxiv.org/pdf/2007.03405.pdf
- a survey on applications of AI in fighting against covid-19: https://arxiv.org/pdf/2007.02202.pdf
- IoT for current covid-19 and future pandemics: an exploratory study: https://arxiv.org/pdf/2007.11147.pdf

one weird trick for parallelizing CNNs: https://arxiv.org/pdf/1404.5997v2.pdf
http://course18.fast.ai/part2.html
why train what you can code? Rekall: a compositional approach to video analysis: https://dawn.cs.stanford.edu/2019/10/09/rekall/
infrastructure for usable ML: the stanford dawn project: https://arxiv.org/pdf/1705.07538.pdf
"resnet inference energy cost"
noscope: optimizing NN queries over video at scale: https://arxiv.org/pdf/1703.02529.pdf
E^2-Train: training SOTA CNNs with over 80% energy savings: https://arxiv.org/pdf/1910.13349.pdf

deepmind, deep RL and its neuroscientific implications: https://deepmind.com/research/publications/Deep-Reinforcement-Learning-and-its-Neuroscientific-Implications
yoshua bengio: from system 1 DL to system 2 DL: https://www.youtube.com/watch?v=T3sxeTgT4qc
seems interesting: https://www.wandb.com/papers
don guy seems interesting: https://www.youtube.com/playlist?list=PLpP2qGSxCw-e0nMetkx41JVrdcivVxUPm, https://www.pugetsystems.com/all_hpc.php

spectral normalization, seems to fix problems with the discriminator

long term goal is to be able to:
- do research on my own with language models
- paragraph recognition
- do research on RL
- accurately model physics

https://medium.com/dataseries/google-deepminds-dreamer-is-a-reinforcement-learning-agent-that-can-solve-long-horizon-tasks-5faa6f6b63b
https://singularityhub.com/2020/07/26/deepminds-newest-ai-programs-itself-to-make-all-the-right-decisions

proximal policy optimization, another popular RL method

https://www.lesswrong.com/posts/fRsjBseRuvRhMPPE5/an-overview-of-11-proposals-for-building-safe-advanced-ai
https://www.lesswrong.com/posts/Mzrs4MSi58ujBLbBG/you-can-probably-amplify-gpt3-directly
breaking the quadratic attention bottleneck in transformers: https://www.reddit.com/r/MachineLearning/comments/hxvts0/d_breaking_the_quadratic_attention_bottleneck_in/
https://mailchi.mp/2485e6b42012/an-102-meta-learning-by-gpt-3-and-a-list-of-full-proposals-for-ai-alignment?e=e50845312e

ddpg algorithm

world models: https://arxiv.org/pdf/1803.10122.pdf

https://www.reddit.com/r/MachineLearning/comments/g16s40/r_metalearning_in_neural_networks_a_survey/

https://towardsdatascience.com/visual-attention-model-in-deep-learning-708813c2912c
https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html

https://dailynous.com/2020/07/30/philosophers-gpt-3/

crafting papers on ML: https://pdfs.semanticscholar.org/3efc/b97c1de1c87832a7a1d99e91801992a938ec.pdf

https://www.cs.cmu.edu/afs/cs/academic/class/15883-f15/slides/

scikit-learn is mentioned a whole lot, so what does it actually offer?

http://worrydream.com/MagicInk/
"how much computation the brain does"
- https://www.cs.cmu.edu/afs/cs/academic/class/15883-f15/slides/
- https://www.cs.cmu.edu/afs/cs/academic/class/15883-f15/slides/marr.pdf
- http://www.cs.utexas.edu/~dana/Book1.pdf
- https://www.frontiersin.org/articles/10.3389/fnsys.2016.00095/full

meta learning through hebbian plasticity: https://www.youtube.com/watch?v=v2GRWzIhaqQ

https://www.reddit.com/r/MachineLearning/comments/i9kztq/d_hidden_gems_and_underappreciated_resources/

http://www.argmin.net/2018/06/25/outsider-rl/
http://karpathy.github.io/2016/05/31/rl/

may be deep RL introspection in our current systems help us reason about this take off scenario better

on the measure of intelligence: https://arxiv.org/pdf/1911.01547.pdf

https://towardsdatascience.com/td-in-reinforcement-learning-the-easy-way-f92ecfa9f3ce
https://towardsdatascience.com/summary-of-tabular-methods-in-reinforcement-learning-39d653e904af

DJ SEO's neural dust: https://arxiv.org/pdf/1307.2196.pdf
neosensory throughput: http://ww-w.eagleman.com/papers/novich_eagleman_2015.pdf

https://www.acrobiosystems.com/P3103-SARS-CoV-2-%28COVID-19%29-S1-protein-His-Tag.html

this as reference for the NMRI model: https://deepmind.com/blog/article/neural-scene-representation-and-rendering

https://distill.pub/2017/aia/
http://lernapparat.de/

https://github.com/gordicaleksa/pytorch-original-transformer

https://syncedreview.com/2020/11/06/deepmind-proposes-graph-theoretic-investigation-of-the-multiplayer-games-landscape

could a neuroscientist understand a microprocessor: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268
https://www.sciencemag.org/news/2020/11/game-has-changed-ai-triumphs-solving-protein-structures
https://www.genome.gov/about-genomics/fact-sheets/Sequencing-Human-Genome-cost
architecture of sars-cov-2 transcriptome: https://www.sciencedirect.com/science/article/pii/S0092867420304062
d614g mutation: https://www.nature.com/articles/s41586-020-2895-3

hopfield networks is all you need: https://arxiv.org/pdf/2008.02217.pdf

https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5641975/
https://pubmed.ncbi.nlm.nih.gov/25561484/

curious stuff:
- https://openai.com/blog/reinforcement-learning-with-prediction-based-rewards/
- https://vimeo.com/238243932
- https://www.ijcai.org/Proceedings/2017/0344.pdf
- https://arxiv.org/pdf/1606.01868.pdf
- https://www.youtube.com/watch?v=0yI2wJ6F8r0
- rainbow: https://arxiv.org/pdf/1710.02298v1.pdf

that combined knowledge thing:
https://deepmind.com/blog/article/neural-scene-representation-and-rendering
https://science.sciencemag.org/content/sci/360/6394/1204.full.pdf?ijkey=kpkRRXA1ckHD6&keytype=ref&siteid=sci

mass production: https://www.reddit.com/r/Entrepreneur/comments/9n8xyj/inventrepreneurship_i_took_an_idea_to_mass/
ttt diagrams: https://www.tf.uni-kiel.de/matwis/amat/iss/kap_8/illustr/s8_4_3a.html

https://fold.it/portal/node/2010076
https://fold.it/portal/node/2007798
https://www.reddit.com/r/MachineLearning/comments/k4n3m2/d_deepminds_alphafold_2_explained_ai_breakthrough/

actually try to implement the attention idea that creates consciousness

also see how advanced stuff-pickup programs are, and can they do stuff really freeflow?

try to create an agent that has some sense of higher dimensions

stuff I really shouldn't put in nodes cause I want to do them so bad:
- https://people.cs.umass.edu/~pthomas/courses/CMPSCI_687_Fall2020/687_F20.pdf
- https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html

limited memory: https://arxiv.org/abs/2002.05645v5
dyson sphere calculations: https://arxiv.org/pdf/2006.16734.pdf

also, several ideas for representing chemical structures:
- smiles (are you kidding me?)
- plain 2d image, and use convs
- morgan fingerprints, best used with random forests or sth like that
- my idea, kinda like an extended version of gravity attention thingy, but with fixed length features coming from variable length tokens through multiple layers
- this is actually golden. Just simple chemical domain classification (kidney/tooth/CNS/...), but does demonstrate good ability to represent chemicals: https://pubs.acs.org/doi/10.1021/acs.jcim.9b00236#
some lackluster papers:
- https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2523-5
- file:///home/kelvin/Downloads/computers-10-00074.pdf
- DRL, also seems golden: https://pubs.acs.org/doi/full/10.1021/acscentsci.7b00492

remaining model stuff:
- modelling kerosene combustion: https://arxiv.org/pdf/2003.00428.pdf
- nn in chemistry: http://web.uni-plovdiv.bg/plamenpenchev/mag/files/ang_chem2.pdf
- alphafold2 paper: https://www.nature.com/articles/s41586-021-03828-1
- dimensionality reduction in neural data analysis: https://xcorr.net/2021/07/26/dimensionality-reduction-in-neural-data-analysis/

talking about fingerprints, there are a few ideas:
- https://www.rdkit.org/UGM/2012/Landrum_RDKit_UGM.Fingerprints.Final.pptx.pdf
- https://towardsdatascience.com/random-matrix-theory-the-best-classifier-for-prediction-of-drug-binding-f82613fb48ed
- predefined features (human made), binary bit has it or not
- https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-00445-4

eterna again

https://sk.ru/

https://github.com/dair-ai/Transformers-Recipe/blob/main/README.md
https://github.com/gordicaleksa/pytorch-original-transformer
consciousness: https://twitter.com/brandondamos/status/1493658995818651655
tokamak stuff: https://twitter.com/pfau/status/1494001370134896650
https://bounded-regret.ghost.io/measurement-and-optimization/

https://en.wikipedia.org/wiki/Metal%E2%80%93organic_framework
Reprogramming to recover youthful epigenetic information and restore vision

ginkgo: https://www.youtube.com/watch?v=OViMxELBYew
comps in DL: https://twitter.com/samscub/status/1491556055796510722
https://jobs.lever.co/Insitro/30c30777-1527-4474-ad70-1f6332b7fea5

anon doc again, https://en.wikipedia.org/wiki/2011_Egyptian_revolution

create ai tool to recognize tables, crop them out correctly and perform ocr on them, to help me analyze bmw i3

"deep learning in alternate reality"
https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw/videos
https://arxiv.org/pdf/2103.00020.pdf

https://en.wikipedia.org/wiki/MXenes

for when I'm fluent in russian: https://www.youtube.com/watch?v=ZtBrQb-qP5M

predict parallel or antiparallel range in a sheet
grab all human proteins, see their locations
uv-vis for lots of containers, to see if that makes a difference
paddleocr
pytorch fuse kernels
netflix prize contest
latent factor models
https://twitter.com/MoAlQuraishi/status/1539589308893597698
see how that aki bot or sth works
see how napas works
stem cells reversal easy and reliable? That's new
what cloudflare really offers again? and how does their cdn work?
https://meta.serverfault.com/questions/1986/what-are-the-canonical-answers-weve-discovered-over-the-years
intelligence explosion kinetics
redis pool
https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP
security: https://www.fireeye.com/products/helix/what-is-siem-and-how-does-it-work.html
make genome lookup fast, so that whenever I have a new gene, I can quickly find it against my own genome.
may be the old t-sne didn't work well because it's not deep enough?
k1ui add interface as k1ui in k1lib. Also add token, to make it secure

face id on screens, then continue on k1ui

https://github.com/pyscf/pyscf
uniquac python:
- https://github.com/gustavochm/phasepy
- https://thermo.readthedocs.io/

ongoing:
- decompose uv-vis
- predict alpha helix locations
- deconvolve x-ray crystal, mri, telescope array data
- k1ui, truly automating btd6
- k1ui thingy, create program to automatically cutout images similar to given factorio examples during playthrough
- predict energy of docking
- predict chemical properties given only smiles
- predict the probability fields directly given structure
- predict molecule evolution, basically time-consistent RL
- predict where genes, introns, exons, motifs are
- paragraph, in case I can't come up with the solution on my own: https://arxiv.org/pdf/2012.03868.pdf
- split 2 audio apart, say me and twin
- clip

really perfect rdp for desktop, with legit auth and whatnot, cause I might want to access it directly
hadoop distributed file system
also understand deeply how db transactions work and how they're implemented
apache spark again
b trees again, for disk perf

honestly alphafold's architecture is not that amazing, and is pretty straightforward actually, so try to do it directly
pymol

try to reconstruct the 3d structure from 2d distance maps directly instead of running SGD on the 3d points themselves, so that it's end-to-end differentiable
quarternions again

really do amber fields correctly this time

mlexps send session token over

automate survivors in sas 4. First record 2 playthroughs, and make sure I can really aim stuff, move around and whatnot. Do btd6 first, because it's simpler and faster, so that I have a clear plan of what to do
after k1ui and tested out on btd6, do paperclip

https://www.youtube.com/c/comsol/videos
https://future.com/the-rise-of-domain-experts-in-deep-learning
https://www.youtube.com/watch?v=OEUT0RoU5hs&ab_channel=COMSOL
https://cdn.comsol.com/doc/5.5/IntroductionToCOMSOLMultiphysics.pdf
https://www.comsol.com/models

do a network that can skip time effectively, but using a well, pre-defined domain. Then try to apply it to the gravity prediction problem and eventually molecular evolution

compact open frame computer case itx
may be download all cif files from here? https://www.wwpdb.org/ftp/pdb-ftp-sites
create a system that searches for proteins with roughly the same shape?

also create a system that integrates searches to ncbi's tools?
text databases, complete language model, to really prove out attention, then do mo/9-alpha

starting out as a vae, then do a gan. Transition smoothly
freezing subnetworks after vae pretraining, so that they don't go nuts and sort of have to stick with the current implementation
try style transfer, but on a much bigger image
test out diffusion component alone. May be have to do another network where I can feed in random varibles to direct it, for the specific time step component
recognize protein shapes and return similar structures that look kinda the same

think about time scales on different spatial scales. Why do things move so fast? Do momentum balance works as usual?

tests out contrastive learning, supervised, so pulling same class together, diff classes out, with active learning
also really track uptime data

celeb-a do interactive, also the splitting tables thingy
yolo, when free: https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/

setup rsync with phone to backup everything

aspen:
- co2 + cao = caco3
- h2co3 <-> h2o + co2, just to see if aspen can cope with this relatively strange system
- co2 + koh, then ca(oh)2 transfer
- cao + h2o, pretty simple, and the reverse
- caco3 <-> ca(oh)2 + h2co3
- mgcl2 + ca(oh)2
- caco3 + ca(oh)2, which is preferred?
- fe3o4 + al

try to run through stable diffusion, not train it, cause I might need to start integrating existing systems

contrastive learning, really figure out how much information can I extract out of the latent variable. Can I easily filter out blurred images after giving it only 10 supervised examples and 10M unsupervised examples? If it's possible, then I can potentially just use that network everywhere, to quickly train up whatever I want. Kinda like classic pretraining, but more powerful and generalizable.

generate a bunch of comsol time-dependent simulations, then try to predict that using a network

blender pixel depth data:
- "blender python z depth"
- https://blender.stackexchange.com/questions/180391/how-to-get-z-distance-not-depth-from-camera-to-object-for-every-pixel-in-the-f
- https://developer.blender.org/T100417
- https://blenderartists.org/t/getting-the-depth-of-every-pixel-to-the-center-of-projection-of-the-camera-in-blender/1328065
- https://www.cityscapes-dataset.com/

quickly do unet

sim/chem:
- https://www.comsol.com/model/download/909321/models.mph.laser_heating_wafer.pdf
- https://www.controlloopfoundation.com/downloads/about-the-book/Control-Loop-Foundation-Overview.pdf
- https://www.youtube.com/c/Chemistrywithcode/videos
- https://en.wikipedia.org/wiki/Retrosynthetic_analysis

model capacity/data points in function/

kaparthy llm: https://www.youtube.com/watch?v=PaCmpygFfXo
